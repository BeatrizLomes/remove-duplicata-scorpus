#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AnÃ¡lise de Duplicatas em Arquivo CSV da Scopus
Este script identifica e exibe duplicatas por DOI e por TÃ­tulo
"""

import pandas as pd
import os
import sys
from datetime import datetime

# ==============================================================================
# CONFIGURAÃ‡ÃƒO DE SAÃDA DUAL (Terminal + Arquivo)
# ==============================================================================
class DualOutput:
    """Classe para escrever simultaneamente no terminal e em arquivo"""
    def __init__(self, filename):
        self.terminal = sys.stdout
        self.log = open(filename, 'w', encoding='utf-8')
    
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()
    
    def close(self):
        self.log.close()

# Criar arquivo de saÃ­da com timestamp
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_file = f"analise_duplicatas_resultado_{timestamp}.txt"
sys.stdout = DualOutput(output_file)

# ==============================================================================
# 1. LEITURA DO ARQUIVO CSV
# ==============================================================================
print("="*80)
print("ANÃLISE DE DUPLICATAS - ARQUIVO SCOPUS")
print("="*80)
print()

# Nome do arquivo CSV
csv_file = "export_8f77fb33-532c-470c-9e41-4482d02a30ec_2025-10-05T231503.385218.csv"

# Verificar se o arquivo existe
if not os.path.exists(csv_file):
    print(f"ERRO: Arquivo '{csv_file}' nÃ£o encontrado!")
    exit(1)

# Ler o arquivo CSV
print(f"ğŸ“„ Lendo arquivo: {csv_file}")
df = pd.read_csv(csv_file)
print(f"âœ… Arquivo carregado com sucesso!")
print(f"   Total de registros: {len(df)}")
print(f"   Colunas encontradas: {list(df.columns)}")
print()

# ==============================================================================
# 2. ANÃLISE DE DUPLICATAS POR DOI
# ==============================================================================
print("="*80)
print("ANÃLISE 1: DUPLICATAS POR DOI")
print("="*80)
print()

# Remover valores nulos de DOI para anÃ¡lise
df_doi_valido = df[df['DOI'].notna()].copy()
print(f"ğŸ“Š Registros com DOI vÃ¡lido: {len(df_doi_valido)}")
print(f"ğŸ“Š Registros sem DOI: {len(df) - len(df_doi_valido)}")
print()

# Identificar DOIs duplicados
# Considera duplicado quando um DOI aparece mais de 1 vez
duplicados_doi = df_doi_valido[df_doi_valido.duplicated(subset=['DOI'], keep=False)]

if len(duplicados_doi) > 0:
    # Ordenar por DOI para facilitar visualizaÃ§Ã£o
    duplicados_doi = duplicados_doi.sort_values('DOI')
    
    print(f"âš ï¸  DUPLICATAS ENCONTRADAS: {len(duplicados_doi)} registros duplicados")
    print(f"   NÃºmero de DOIs Ãºnicos duplicados: {duplicados_doi['DOI'].nunique()}")
    print()
    
    # Exibir tabela com as colunas mais importantes
    print("ğŸ“‹ Tabela de Duplicatas por DOI:")
    print("-" * 80)
    
    # Selecionar colunas relevantes
    colunas_exibir = ['DOI', 'Title', 'Authors', 'Year']
    tabela_doi = duplicados_doi[colunas_exibir].copy()
    
    # Truncar tÃ­tulos longos para melhor visualizaÃ§Ã£o
    tabela_doi['Title'] = tabela_doi['Title'].apply(
        lambda x: (x[:80] + '...') if isinstance(x, str) and len(x) > 80 else x
    )
    
    # Truncar autores longos
    tabela_doi['Authors'] = tabela_doi['Authors'].apply(
        lambda x: (x[:50] + '...') if isinstance(x, str) and len(x) > 50 else x
    )
    
    # Configurar pandas para exibir todas as linhas e colunas
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', None)
    pd.set_option('display.max_colwidth', None)
    
    print(tabela_doi.to_string(index=False))
    print()
    
    # EstatÃ­sticas detalhadas por DOI duplicado
    print("ğŸ“Š Detalhamento dos DOIs duplicados:")
    print("-" * 80)
    contagem_doi = duplicados_doi['DOI'].value_counts()
    for doi, count in contagem_doi.items():
        print(f"   DOI: {doi}")
        print(f"   Aparece {count} vezes")
        print()
else:
    print("âœ… Nenhuma duplicata encontrada por DOI!")
    print()

# ==============================================================================
# 3. ANÃLISE DE DUPLICATAS POR TÃTULO
# ==============================================================================
print("="*80)
print("ANÃLISE 2: DUPLICATAS POR TÃTULO")
print("="*80)
print()

# Remover valores nulos de Title para anÃ¡lise
df_title_valido = df[df['Title'].notna()].copy()
print(f"ğŸ“Š Registros com TÃ­tulo vÃ¡lido: {len(df_title_valido)}")
print(f"ğŸ“Š Registros sem TÃ­tulo: {len(df) - len(df_title_valido)}")
print()

# Normalizar tÃ­tulos para melhor comparaÃ§Ã£o (remover espaÃ§os extras, converter para minÃºsculas)
df_title_valido['Title_Normalizado'] = df_title_valido['Title'].str.strip().str.lower()

# Identificar tÃ­tulos duplicados
duplicados_title = df_title_valido[df_title_valido.duplicated(subset=['Title_Normalizado'], keep=False)]

if len(duplicados_title) > 0:
    # Ordenar por tÃ­tulo normalizado para facilitar visualizaÃ§Ã£o
    duplicados_title = duplicados_title.sort_values('Title_Normalizado')
    
    print(f"âš ï¸  DUPLICATAS ENCONTRADAS: {len(duplicados_title)} registros duplicados")
    print(f"   NÃºmero de TÃ­tulos Ãºnicos duplicados: {duplicados_title['Title_Normalizado'].nunique()}")
    print()
    
    # Exibir tabela com as colunas mais importantes
    print("ğŸ“‹ Tabela de Duplicatas por TÃ­tulo:")
    print("-" * 80)
    
    # Selecionar colunas relevantes (usando o tÃ­tulo original, nÃ£o o normalizado)
    colunas_exibir = ['DOI', 'Title', 'Authors', 'Year']
    tabela_title = duplicados_title[colunas_exibir].copy()
    
    # Truncar tÃ­tulos longos para melhor visualizaÃ§Ã£o
    tabela_title['Title'] = tabela_title['Title'].apply(
        lambda x: (x[:80] + '...') if isinstance(x, str) and len(x) > 80 else x
    )
    
    # Truncar autores longos
    tabela_title['Authors'] = tabela_title['Authors'].apply(
        lambda x: (x[:50] + '...') if isinstance(x, str) and len(x) > 50 else x
    )
    
    print(tabela_title.to_string(index=False))
    print()
    
    # EstatÃ­sticas detalhadas por tÃ­tulo duplicado
    print("ğŸ“Š Detalhamento dos TÃ­tulos duplicados:")
    print("-" * 80)
    # Criar um mapeamento do tÃ­tulo normalizado para o original
    titulo_map = duplicados_title.groupby('Title_Normalizado')['Title'].first()
    contagem_title = duplicados_title['Title_Normalizado'].value_counts()
    
    for title_norm, count in contagem_title.items():
        titulo_original = titulo_map[title_norm]
        # Truncar tÃ­tulo se muito longo
        titulo_exibir = (titulo_original[:100] + '...') if len(titulo_original) > 100 else titulo_original
        print(f"   TÃ­tulo: {titulo_exibir}")
        print(f"   Aparece {count} vezes")
        print()
else:
    print("âœ… Nenhuma duplicata encontrada por TÃ­tulo!")
    print()

# ==============================================================================
# 4. RESUMO FINAL
# ==============================================================================
print("="*80)
print("RESUMO FINAL DA ANÃLISE")
print("="*80)
print()

print(f"ğŸ“Š ESTATÃSTICAS GERAIS:")
print(f"   Total de registros no arquivo: {len(df)}")
print(f"   Registros com DOI vÃ¡lido: {len(df_doi_valido)}")
print(f"   Registros com TÃ­tulo vÃ¡lido: {len(df_title_valido)}")
print()

print(f"ğŸ” DUPLICATAS POR DOI:")
if len(duplicados_doi) > 0:
    print(f"   âš ï¸  {len(duplicados_doi)} registros duplicados encontrados")
    print(f"   âš ï¸  {duplicados_doi['DOI'].nunique()} DOIs Ãºnicos com duplicatas")
    print(f"   ğŸ“ˆ Taxa de duplicaÃ§Ã£o: {(len(duplicados_doi) / len(df_doi_valido) * 100):.2f}%")
else:
    print(f"   âœ… Nenhuma duplicata encontrada")
print()

print(f"ğŸ” DUPLICATAS POR TÃTULO:")
if len(duplicados_title) > 0:
    print(f"   âš ï¸  {len(duplicados_title)} registros duplicados encontrados")
    print(f"   âš ï¸  {duplicados_title['Title_Normalizado'].nunique()} TÃ­tulos Ãºnicos com duplicatas")
    print(f"   ğŸ“ˆ Taxa de duplicaÃ§Ã£o: {(len(duplicados_title) / len(df_title_valido) * 100):.2f}%")
else:
    print(f"   âœ… Nenhuma duplicata encontrada")
print()

# Verificar se hÃ¡ registros duplicados TANTO por DOI quanto por TÃ­tulo
if len(duplicados_doi) > 0 and len(duplicados_title) > 0:
    # Encontrar interseÃ§Ã£o
    indices_doi = set(duplicados_doi.index)
    indices_title = set(duplicados_title.index)
    intersecao = indices_doi.intersection(indices_title)
    
    print(f"ğŸ”— DUPLICATAS COMUNS (DOI E TÃTULO):")
    print(f"   {len(intersecao)} registros sÃ£o duplicados tanto por DOI quanto por TÃ­tulo")
    print()

print("="*80)
print("FIM DA ANÃLISE")
print("="*80)
print()
print(f"ğŸ’¾ Resultado salvo em: {output_file}")

# Fechar o arquivo de log
sys.stdout.close()
sys.stdout = sys.stdout.terminal  # Restaurar stdout original

